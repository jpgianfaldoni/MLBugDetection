{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# !pip uninstall mlbugdetection\n",
    "# import mlbugdetection\n",
    "from mlbugdetection.monotonic import monotonicity_mse, check_monotonicity\n",
    "from mlbugdetection.critical_values import find_critical_values, highest_and_lowest_indexes\n",
    "from mlbugdetection.calibration import calibration_check\n",
    "from mlbugdetection.sanity import sanity_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manter plots salver disco\n",
    "#classe \n",
    "# help(sanity_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\willi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\willi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\willi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator SVC from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('models/XGBoost/XGBoost.pkl', 'rb') as f:\n",
    "    XGBoost = pickle.load(f)\n",
    "with open('models/LogisticRegression/LogisticRegression.pkl', 'rb') as f:\n",
    "    LR = pickle.load(f)\n",
    "with open('models/RandomForest/RandomForest.pkl', 'rb') as f:\n",
    "    RF = pickle.load(f)\n",
    "with open('models/SVM/SVMTitanic.pkl', 'rb') as f:\n",
    "    SVM = pickle.load(f)\n",
    "models = [XGBoost, LR, RF]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/fraud_new.csv')\n",
    "df_titanic = pd.read_csv('../datasets/TitanicClean.csv')\n",
    "example = df.sample(1)\n",
    "examples = df.sample(100)\n",
    "# example = example.drop('isFraud', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_titanic = df_titanic.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.AnalysisReport at 0x24556b95750>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from .analysis_report import AnalysisReport\n",
    "\n",
    "def check_type_input_model(model):\n",
    "    ''' Check the type of the input model and returns the model object '''\n",
    "    if type(model) == str:\n",
    "        with open(model, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "def sanity_check(model, samples, target):\n",
    "    '''Sanity Test\n",
    "        Analyzes the sanity of a model with samples and \n",
    "        return a bool that represents if the tests passed or not.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn model or str\n",
    "        The model to be used for prediction. Could be a model object or a path to a model file.\n",
    "\n",
    "    samples : pandas DataFrame\n",
    "        The samples to be used for prediction, which the model\n",
    "        need to predict correctly. \n",
    "\n",
    "    target : str\n",
    "        The name of the column containing the target variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool True if the model is sane, False otherwise.\n",
    "    '''\n",
    "    model = check_type_input_model(model)\n",
    "\n",
    "    result = model.predict(samples.drop(target, axis=1))\n",
    "    original = samples[target]\n",
    "\n",
    "    result = pd.Series(result).reset_index(drop=True)\n",
    "    origin = original.reset_index(drop=True)\n",
    "    values = result == origin\n",
    "\n",
    "    if len(values.value_counts().index) == 2:\n",
    "        return False\n",
    "\n",
    "    return values[0]\n",
    "\n",
    "def sanity_check_with_indexes(model, samples, target):\n",
    "    '''Sanity Test With Indexes\n",
    "        Analyzes the sanity of a model with samples and \n",
    "        shows a Analysis Report that shows if the tests passed or not.\n",
    "        If the tests failed, it will show the indexes of the samples that were misclassified.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn model or str\n",
    "        The model to be used for prediction. Could be a model object or a path to a model file.\n",
    "\n",
    "    samples : pandas DataFrame\n",
    "        The samples to be used for prediction, which the model\n",
    "        need to predict correctly. \n",
    "\n",
    "    target : str\n",
    "        The name of the column containing the target variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     AnalysisReport object with following attributes:\n",
    "        For more information:\n",
    "        >>> from mlbugdetection.analysis_report import AnalysisReport\n",
    "        >>> help(AnalysisReport)\n",
    "\n",
    "    model_name : str\n",
    "        Name of the model being analysed.\n",
    "    \n",
    "    analysed_feature : str\n",
    "        Name of the feature being analysed.\n",
    "\n",
    "    metrics : dictionary\n",
    "        Dictionary with all the calculated metrics, such as:\n",
    "        \n",
    "        'sanity' : bool\n",
    "            If the model is sane or not.\n",
    "\n",
    "        'sanity_indexes': List\n",
    "            List of indexes of the samples that were misclassified.\n",
    "\n",
    "    '''\n",
    "    model = check_type_input_model(model)\n",
    "    report = AnalysisReport()\n",
    "\n",
    "    result = model.predict(samples.drop(target, axis=1))\n",
    "    original = samples[target]\n",
    "\n",
    "    result = pd.Series(result).reset_index(drop=True)\n",
    "    origin = original.reset_index(drop=True)\n",
    "    values = result == origin\n",
    "    \n",
    "    report.model_name = type(model).__name__\n",
    "    report.analysed_feature = target\n",
    "\n",
    "    if len(values.value_counts().index) == 2:\n",
    "        report.metrics[\"sanity\"] = False\n",
    "        report.metrics[\"sanity_indexes\"] = values[values==False].index.to_list()\n",
    "        return report\n",
    "\n",
    "    report.metrics[\"sanity\"] = True\n",
    "    report.metrics[\"sanity_indexes\"] = []\n",
    "    return report\n",
    "\n",
    "sanity_check_with_indexes(XGBoost, df, 'isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.AnalysisReport at 0x24556bccdc0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idk = df.iloc[221:250,:]\n",
    "sanity_check(XGBoost, idk, 'isFraud')\n",
    "sanity_check_with_indexes(XGBoost, idk, 'isFraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Others analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_titanic.columns:\n",
    "    if c != 'isFraud':\n",
    "        minV = df_titanic[c].min()\n",
    "        maxV = df_titanic[c].max()\n",
    "        teste = check_monotonicity(c,minV,maxV,example_titanic, \"models/SVM/SVMTitanic.pkl\", 150)\n",
    "        # teste = check_monotonicity(c,minV,maxV,example_titanic, SVM, 150)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teste)\n",
    "teste.save_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teste.errors)\n",
    "print(teste.warnings)\n",
    "print(teste.metrics)\n",
    "print(teste.model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_titanic.columns:\n",
    "    if c != 'isFraud':\n",
    "        minV = 100\n",
    "        maxV = 100\n",
    "        find_critical_values(SVM, example_titanic, c, minV, maxV, step = 1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if c != 'isFraud':\n",
    "        minV = df[c].min()\n",
    "        maxV = df[c].max()\n",
    "        for model in models:\n",
    "            teste3 = find_critical_values(model, example, c, minV, maxV )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if c != 'isFraud':\n",
    "        minV = df[c].min()\n",
    "        maxV = df[c].max()\n",
    "        for model in models:\n",
    "            # check_monotonicity(c,minV,maxV,example, model, 150, plot_graph=True)\n",
    "            check_monotonicity(c,minV,maxV,example, model, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    teste2 = calibration_check(\"isFraud\", model, df)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste2.save_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste2.graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "970abb1aa500516e602ecbb4cfb7dea7bc4d134d3c58454769ed100db73fe7f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
